{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756a0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e38879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/processed\"\n",
    "SPLIT_DIR = \"../data/split\"\n",
    "\n",
    "# create split dirs\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"real\", \"fake\"]:\n",
    "        os.makedirs(os.path.join(SPLIT_DIR, split, cls), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5ae2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted into train/val/test\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test split\n",
    "def split_dataset(src_dir, dst_dir, train_ratio=0.7, val_ratio=0.15):\n",
    "    for cls in [\"real\", \"fake\"]:\n",
    "        files = os.listdir(os.path.join(src_dir, cls))\n",
    "        \n",
    "        # train/test/val split\n",
    "        train_files, temp_files = train_test_split(files, test_size=(1-train_ratio), random_state=42)\n",
    "        val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n",
    "\n",
    "        # copy files\n",
    "        for split, split_files in zip([\"train\", \"val\", \"test\"], [train_files, val_files, test_files]):\n",
    "            for f in split_files:\n",
    "                src = os.path.join(src_dir, cls, f)\n",
    "                dst = os.path.join(dst_dir, split, cls, f)\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "split_dataset(DATA_DIR, SPLIT_DIR)\n",
    "print(\"Data splitted into train/val/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534c1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9109d8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes fake, real. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSPLIT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m val_dataset   = datasets.ImageFolder(os.path.join(SPLIT_DIR, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m), transform=transform_eval)\n\u001b[32m      3\u001b[39m test_dataset  = datasets.ImageFolder(os.path.join(SPLIT_DIR, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m), transform=transform_eval)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deept\\Desktop\\ClgProj\\DeepDetect-DeepFake\\dd_dfenv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deept\\Desktop\\ClgProj\\DeepDetect-DeepFake\\dd_dfenv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:150\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m    149\u001b[39m classes, class_to_idx = \u001b[38;5;28mself\u001b[39m.find_classes(\u001b[38;5;28mself\u001b[39m.root)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m samples = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m.loader = loader\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.extensions = extensions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deept\\Desktop\\ClgProj\\DeepDetect-DeepFake\\dd_dfenv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:203\u001b[39m, in \u001b[36mDatasetFolder.make_dataset\u001b[39m\u001b[34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    199\u001b[39m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[32m    201\u001b[39m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deept\\Desktop\\ClgProj\\DeepDetect-DeepFake\\dd_dfenv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:104\u001b[39m, in \u001b[36mmake_dataset\u001b[39m\u001b[34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m         msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Found no valid file for the classes fake, real. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(os.path.join(SPLIT_DIR, \"train\"), transform=transform_train)\n",
    "val_dataset   = datasets.ImageFolder(os.path.join(SPLIT_DIR, \"val\"), transform=transform_eval)\n",
    "test_dataset  = datasets.ImageFolder(os.path.join(SPLIT_DIR, \"test\"), transform=transform_eval)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)} | Val size: {len(val_dataset)} | Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f249d063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading datasets: Found no valid file for the classes fake, real. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_dataset = datasets.ImageFolder(os.path.join(SPLIT_DIR, \"train\"), transform=transform_train)\n",
    "    val_dataset = datasets.ImageFolder(os.path.join(SPLIT_DIR, \"val\"), transform=transform_eval)\n",
    "    test_dataset = datasets.ImageFolder(os.path.join(SPLIT_DIR, \"test\"), transform=transform_eval)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Train size: {len(train_dataset)} | Val size: {len(val_dataset)} | Test size: {len(test_dataset)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b1890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
